{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summaries\n",
    "\n",
    "### Descriptive Statistics\n",
    "\n",
    "### Central Tendency\n",
    "\n",
    "### Variance\n",
    "\n",
    "### Covariance\n",
    "\n",
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "### Measurement\n",
    "\n",
    "### Error\n",
    "\n",
    "### Random Number Generation\n",
    "\n",
    "### Hypothesis Testing\n",
    "\n",
    "### A/B Testing\n",
    "\n",
    "### Confidence Intervals\n",
    "\n",
    "### P-Values\n",
    "\n",
    "### ANOVA\n",
    "\n",
    "### T-Test\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "### Regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Limit Theorem\n",
    "\n",
    "In any trial we obtain an outcome based on the trial we are conducting. For example, if we are flipping coins we may see that as we continue to flip a coin, the proability of it being heads is 50%. A trial only produces an estimate, because we know that it won't be perfect. If we make many estimates, the Central Limit Theorem dictates that the distribution of these estimates will look like a normal distribution. The zenith of this distribution will line up with the true value that the estimates should take on. \n",
    "\n",
    "In statistics, the peak of the normal distribution lines up with the mean, and that's exactly what we observed. Thus, given multiple trials as our data, the CLT suggest that we can hone in on the theoretical ideal given by probability, even when we don't know the true probability. \n",
    "\n",
    "CLT lets us know that the average of many trials means will approach the true mean, the three sigma rule will tell us how much the data will be spread out around this mean. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three Sigma Rule\n",
    "\n",
    "Also known as the empirical rule or 68 - 95 - 99.7 rule, is an expression of how many of our observations fall within a certain distance of the mean. Remember that the standard deviation is the average distance an observation in the data set is from the mean. It says, given a **normal distribution**, 68% of your observations will fall between one standard deviation of the mean. 95% will fall within two and 99.7% will fall within three. \n",
    "\n",
    "This allows us to know how much data is contained under different intervals of a normal distribution. \n",
    "\n",
    "![threesigma](three_sigma.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score\n",
    "\n",
    "A simple calculation that answers the question \"Given a data point, how many standard deviations is it away from the mean\". The equation is\n",
    "\n",
    "$$ z = \\frac{x_i - \\mu}{\\sigma}$$\n",
    "\n",
    "where, $\\mu$ = the mean, $\\sigma$ = the standard deviation, and $x_i$ is a data point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
