{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Models to Data\n",
    "\n",
    "Goal: How to fit statistical models to data to help answer research questions\n",
    "We are fitting models to data not the other way around. We specify models based on theory or subject matter knowledge and then we fit those models to the data that we've collected, and the idea here is that the variables in our dataset follow distributions or have certain relationships. The models that we fit to the datasets describe those distributions or describe the relationships.\n",
    "\n",
    "**Why?**\n",
    "\n",
    "\n",
    "\n",
    "Estimate model parameters + sampling variance = make inference about parameters by testing hypotheses or generating confidence intervals\n",
    "\n",
    "### Example: Test Performance and Age\n",
    "\n",
    "Suppose we're interested in some measure of test performance for college students and the relationship of test performance with age. So, our variable of interest is test performance and suppose that that ranges anywhere between zero and eight points and can take on a number of values between those endpoints, zero and eight. A possible predictor that we're interested in to answer a research question is age and we standardize age with respect to the mean and the standard deviation of age. We want to know if age can predict the value of test performance.\n",
    "\n",
    "We believe that age has a curvilinear relationship with performance, moderate values of age leads to best performance, while smaller or larger values of age leads to worse performance. \n",
    "\n",
    "Goals:\n",
    "1. estimate marginal mean of performance across all ages\n",
    "2. estimate mean performance conditional on age\n",
    "\n",
    "we're going to consider two different modeling approaches. We're going to start with what's called a mean only model for test performance. We're going to assume that test performance follows a normal distribution overall defined by a particular mean and defined by a particular variance. So, based on this particular model, we're estimating two parameters; the mean of that normal distribution and the variance of that normal distribution. We think that a normal distribution represents a good model for the observed values on test performance and we're only interested in modeling the overall mean. \n",
    "\n",
    "For our second objective, conditional on age, we believe that performance follows again a normal distribution where the mean is defined by a quadratic function of age.\n",
    "\n",
    "$a+b*age + c*age^2 $ (three parameters: a, b and c) and variance $\\sigma^2$ (one parameter)\n",
    "\n",
    "In addition to the three parameters we are also estimating the variance conditional on age. So we relate test performance to this quadratic function and this quadratic function captures our theory about the curvilinear relationship between age and test performance. \n",
    "\n",
    "### The Data: Peformance\n",
    "\n",
    "Example marginal distribution of performance (n = 200) via Histogram and Normal Q-Q plot - does the normal distribution seem like a reasonable model for performance. Visualize the relationship between age and test performance via scatter plot - support for our theory regarding curvilinear relationship?\n",
    "\n",
    "### Fit the mean only model\n",
    "Fit regression model to performance data\n",
    "\n",
    "perf = m + e\n",
    "1st parameter (unknown constant) \n",
    "\n",
    "m = marginal mean\n",
    "\n",
    "First model we are regressing test performance on a simple mean, we are saying performance can be predicted by a mean\n",
    "\n",
    "Errors are normally distributed with a mean 0 and variance $\\sigma^2$ where e ~ N(0, $\\sigma^2$) - 2nd parameter\n",
    "\n",
    "E is the random error that defines each observation's deviation from the overall mean\n",
    "\n",
    "We made an assumption that the error follows a normal distribution, this is something we need to check. \n",
    "\n",
    "#### Assess the fit of mean only model \n",
    "\n",
    "residuals = realized values of random errors, = observed performance - estimated mean m\n",
    "\n",
    "- example realized residuals via histogram and normal Q-Q plot to see if normal model is good fit for data\n",
    "\n",
    "- if normal model was not a good fit, we would see large deviations from normality in realized residuals\n",
    "\n",
    "### Fit the conditional model\n",
    "\n",
    "Fit regression model: regress performance on age and $age^2$\n",
    "\n",
    "$perf = a + b*age + c*age^2 + e$ where e ~ N(0, $\\sigma^2$)\n",
    "\n",
    "a, b, and c = three parameters we want to estimate, these are called regression coefficients, and e = random error\n",
    "\n",
    "\n",
    "#### Assess the fit of conditional model \n",
    "\n",
    "See if residuals (realized values of e)\n",
    "- appear to be normally distributed\n",
    "- are symmetrically distributed around zero with constant variance\n",
    "\n",
    "If the residuals are not symmetrically scattered around zero, model fit looks poor and poor predictions are low and high values of age, leading to a higher variance. This is why its important to visualize the residual plot after making assumptions about the model to the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type of Variables in Statistical Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Study Designs Generate Different Types of Data\n",
    "\n",
    "So why does this matter? When we fit a model to a particular variable in a set of data against some dependent variable of interest, our goal is to estimate the parameters that best describe the distribution of that variable. So far we've introduced simple examples of estimating the means and variances of dependent variables, possibly conditional on the values of other independent variables. But another key aspect of estimating the distributions of variables of interest is the possibility that different values on a dependent variable of interest may be correlated with each other, for one reason or another. And often times, different types of study designs can introduce those correlations between different values on the same dependent variable. And this may be a feature of the data that we need to account for when specifying our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives of Model Fitting: Inference vs Prediction\n",
    "\n",
    "#### Objective 1: Making Inference\n",
    "t statistic equals the estimate minus null hypothesis divided by the standard error shown as \n",
    "\n",
    "$$ t = \\frac{estimate - 0}{standard error} $$\n",
    "\n",
    "We can compute test statistics for each parameter when making inference, this is to asses if they are significant. \n",
    "\n",
    "We would reject our null hypothesis that the parameter is in fact non-zero and that the relationship between age and performance is in fact significant. \n",
    "\n",
    "#### Objective 2: Making Predictions\n",
    "\n",
    "Plug in values to see if the prediction makes sense. Don't forget about the errors - predictions will have uncertainty the poorer the fitted model, the higher the uncertainty. **Need to account for this**.\n",
    "\n",
    "We could predict the 95th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32800"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50 + 25*30 + 2000*16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Predictions and Plotting Uncertainty\n",
    "\n",
    "Always make sure to plot the uncertainty in your graph. Variance!!!\n",
    "\n",
    "We can determine most of our uncertainty using a notion of Standard Errors, STDs prodive how far we expect our estimates to deviate from the truth. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## Confidence Intervals\n",
    "\n",
    "Recall confidence intervals are calculated as:\n",
    "\n",
    "Best Estimate $\\pm$ Margin of Error\n",
    "\n",
    "Sample Slope $\\pm$ \"a few\" * estimated standard error\n",
    "\n",
    "$b_1 \\pm z^* se(b_1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.12556, 0.54476)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2096 - (1.96 * 0.171), 0.2096 + (1.96 * 0.171)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.00484, 0.010839999999999999)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0030 - (1.96 * 0.004), 0.0030 +(1.96 * 0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.013619999999999998, 0.020179999999999997)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0169 - (1.64 * 0.002), 0.0169 + (1.64 * 0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "Test statistic is calculated the same way. calculation is below.\n",
    "\n",
    "$$H_0 : \\beta_1 = 0$$\n",
    "$$H_0 : \\beta_1 \\ne 0$$\n",
    "\n",
    "Same as previously, we do $ \\frac{b_1 - 0}{se(b_1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2257309941520467"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test statistic is, we can get this from the python outpu\n",
    "0.2096 / 0.171"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we cannot reject or fail to reject our Null hypothesis as we don't have a level of significance (alpha) to compare the p-value to. \n",
    "\n",
    "\"With our two-sides p-value of 0.221, we would fail to reject the null hypothesis and cannot conclude that we have a significantly linear relationship between age and the log odds of the probability of successfully completing a cartwheel.\"\n",
    "\n",
    "Logistic regression for a predicted variable with two options\n",
    "- correct/incorrect or success/failure\n",
    "\n",
    "Confidence Intervals and Hypothesis Tests follow similar format as linear regression\n",
    "- changing interpretation to the logistic context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0408107741923882"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.exp(0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope Interpretation\n",
    "\n",
    "For each increase in age by 1 year, the log odds of a successful cartwheel increases by about 0.2096, on average. \n",
    "\n",
    "The logit of y hat is the log odds function\n",
    "\n",
    "$$ logit(\\hat{y}) = -4.42 + 0.2096 * age $$\n",
    "\n",
    "For each year increase in age, the odds of a successful cartwheel increases by about 1.23 ($e^{0.2096}$) times that of the younger age, on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB: Week 2 NHANES\n",
    "\n",
    "### R-squared and correlation\n",
    "\n",
    "In the case of regression with a\n",
    "single independent variable, as we have here, there is a very close\n",
    "correspondence between the regression analysis and a Pearson\n",
    "correlation analysis, which we have discussed earlier in course 2.\n",
    "The primary summary statistic for assessing the strength of a\n",
    "predictive relationship in a regression model is the *R-squared*, which is\n",
    "shown to be 0.207 in the regression output above.  This means that 21%\n",
    "of the variation in SBP is explained by age.  Note that this value is\n",
    "exactly the same as the squared Pearson correlation coefficient\n",
    "between SBP and age, as shown below.\n",
    "\n",
    "There is a second way to interpret the R-squared, which makes use of the fitted values of the regression. The fitted values are predictions of the blood pressure for each person in the data set, based on their covariate values. In this case, the only covariate is age, so we are predicting each NHANES subject's blood pressure as a function of their age. If we calculate the Pearson correlation coefficient between the fitted values from the regression, and the actual SBP values, and then square this correlation coefficient, we see that we also get the R-squared from the regression:\n",
    "\n",
    "Thus, we see that in a linear model fit with only one covariate, the regression R-squared is equal to the squared Pearson correlation between the covariate and the outcome, and is also equal to the squared Pearson correlation between the fitted values and the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5 / (1-0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3\n",
    "\n",
    "### Marginal Linear Regression Models\n",
    "Generalized Estimating Equations\n",
    "\n",
    "GEE can account for observations clustered by grouping, ignoring dependency in data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
